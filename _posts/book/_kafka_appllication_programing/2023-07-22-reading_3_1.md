---
title:  "[카프카] 카프카 브로커/클러스터/주키퍼"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 3장"
post-order: 1                                

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-07-22
last_modified_at: 2023-07-22
---


### 브로커

---

**카프카 클라이언트와 데이터를 주고받기 위한 주체**

- 데이터를 분산 저장하여 장애가 발생하더라도, 안전하게 사용할수 있도록 지원

  → 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장 / 복제

- 하나의 서버에는 한개의 브로커 프로세스 가 실행된다.

**데이터 저장, 전송**

- 프로듀서로부터 데이터를 받으면 카프카 브로커는 `토픽의 파티션`에 데이터를 저장하고, 컨슈머가 데이터를 요청하면 `토픽의 파티션`에 저장된 데이터를 전달
  - 토픽을 생성하면 각 토픽의 파티션 별 디렉토리를 생성한다

    ```bash
    ## TOPIC 생성 
    /kafka_2.12-2.5.0/bin/kafka-topics.sh \
            --create \
            --bootstrap-server $broker \ // Broker 정보
            --topic hello.kafka.11 \                 // Topic 이름
            --replication-factor 1 \.   
     // 레코드 복제 개수 (min(클러스터링된 브로커 개수, 파티션 개수) 보다 같거나 적어야한다)														
     //// 1 : do not replication
     //// 2~ use replication
    
            --partitions 3 \            // topic의 partition 개수
            --config retention.ms=172800000 \ // 로그 보관 주기
    ```

  ![스크린샷 2023-07-17 오후 9.20.19.png](1%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%87%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8F%E1%85%A5%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A5%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%AE%E1%84%8F%E1%85%B5%E1%84%91%E1%85%A5%20f188bb3d608c4eb09608d0182472a3d8/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-07-17_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_9.20.19.png)

- 토픽의 파티션 별 디렉토리 내 파일 정보

  → 카프카는 메모리나 데이터베이스에 데이터를 저장하는것이 아닌 파일시스템을 통해 저장한다.

    ```
    hello.kafka.11 이라는 토픽의 0번 파티션 정보
    ubuntu@nas-kafka-1:~/29095/kafka-logs/hello.kafka.11-0$ ls -al
    total 12
    drwxrwxr-x 2 ubuntu ubuntu     4096 Jul 17 13:02 .
    drwxrwxr-x 5 ubuntu ubuntu     4096 Jul 17 21:24 ..
    ## 메세지의 오프셋을 인덱싱한 정보
    -rw-rw-r-- 1 ubuntu ubuntu 10485760 Jul 17 13:02 00000000000000000000.index
    
    ## 메세지와 메타데이터를 저장한다. 
    -rw-rw-r-- 1 ubuntu ubuntu        0 Jul 17 13:02 00000000000000000000.log
    -rw-rw-r-- 1 ubuntu ubuntu 10485756 Jul 17 13:02 00000000000000000000.timeindex
    -rw-rw-r-- 1 ubuntu ubuntu        8 Jul 17 13:02 leader-epoch-checkpoint
    ```

- 파일을 통해 데이터를 처리하는 카프카의 속도 향상 방법
  - `페이지캐시` 를 사용하여 Disk I/O를 최소화
    - `페이지캐시` : OS에서 파일 I/O 성능 향상을 위해 만들어 놓은 메모리 영역
  - 카프카는 한번 읽은 파일의 내용은 `페이지캐시` 에 저장하고, 캐시에서 데이터를 반환한다.

### **데이터 복제, 싱크**

---

- 클러스터로 묶인 브로커에 레코드를 복제하여, 장애 발생시 데이터를 유실하지 않고 안전하게 사용
- 카프카의 데이터 복제는 `파티션 단위`로 이루어 진다.

![Untitled](1%20%E1%84%8F%E1%85%A1%E1%84%91%E1%85%B3%E1%84%8F%E1%85%A1%20%E1%84%87%E1%85%B3%E1%84%85%E1%85%A9%E1%84%8F%E1%85%A5%20%E1%84%8F%E1%85%B3%E1%86%AF%E1%84%85%E1%85%A5%E1%84%89%E1%85%B3%E1%84%90%E1%85%A5%20%E1%84%8C%E1%85%AE%E1%84%8F%E1%85%B5%E1%84%91%E1%85%A5%20f188bb3d608c4eb09608d0182472a3d8/Untitled.png)

- 팔로워 파티션들은 리더 파티션의 오프셋을 확인하여 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 파티션으로 저장한다. → 이 과정을 `복제` 라고 한다.
  - 많은 파티션에 복제를 하게 되면 나머지 브로커에도 데이터가 복제되므로 복제 개수만큼 저장 용량이 증가한다는 단점이 있다.

### 컨트롤러

---

다수 브로커 중 한대가 컨트롤러 역할을 한다.

1. 다른 브로커들의 상태 체크 후, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 `리더파티션`을 재분배
2. 컨트롤러 역할의 브로커 장애 발생시 다른 브로커가 컨트롤러 역할을 물려받음

### 데이터 삭제

---

- 카프카는 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
  - 데이터 삭제는 오직 `브로커`만 할수 있다.
- 로그 세그먼트
  - 카프카의 데이터 삭제 단위이고, 파일로 이루어져 있다.
  - 다수의 데이터가 들어가 있기 때문에 특정 데이터를 삭제할수 없다.
  - 데이터가 쌓이는 동안 파일 시스템으로 열려있으며, 카프카 브로커에 아래 옵션값이 설정되면 파일시스템이 닫힌다.
    - log.segement.bytes : 설정된 용량만큼 로그파일이 분리된다.
    - [log.sement.ms](http://log.sement.ms) : 로그 파일 저장 시간 (넘으면 삭제)

### 컨슈머 오프셋 저장

---

컨슈머 그룹은 토픽이 특정 파티션으로부터 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다

커밋한 오프셋은 __**consumer_offsets 토픽에 저장된다**

```
## 이 명령어를 통해 consumer group이 각 토픽에 대해 최대 offset, 현재 offset, LAG 정보를 
#### 볼수 있다. 
/kafka_2.12-2.5.0/bin/kafka-consumer-groups.sh \
        --bootstrap-server $broker \
        --group test-group \
        --describe \

GROUP           TOPIC              PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                HOST             CLIENT-ID
test-group      hello.kafka.11     0          3               3               0               consumer-test-group-1-f987e23e-6806-4042-a547-bcc680b2ac0e /125.131.223.100 consumer-test-group-1
test-group      hello.kafka.11     1          7               7               0               consumer-test-group-1-f987e23e-6806-4042-a547-bcc680b2ac0e /125.131.223.100 consumer-test-group-1
test-group      hello.kafka.11     2          3               3               0               consumer-test-group-1-f987e23e-6806-4042-a547-bcc680b2ac0e /125.131.223.100 consumer-test-group-1
```

### 코디네이터

---

클러스터의 다수 브로커 중 한대는 코디네이터의 역할을 수행

- 컨슈머 그룹의 상태를 체크하고, `파티션을 컨슈머에 매칭되도록 분배`

  → 리밸런스


### Zookeeper Bash Shell

---

Zookeeper Bash Shell을 통해 znode를 조회하고 수정할수 있다.

현재 별도의 설정을 하지 않았기 때문에 `/` 밑에 브로커들이 묶인다.

→ 이렇게 되면 이 주키퍼는 하나의 카프카 클러스터만 관리할수 있다.

→ 한 주키퍼 그룹이 다수의 카프카 클러스터를 관리하려면, 브로커들을 `/` 가 아닌 `/{clusterId}` 로 묶어서 관리해야 한다.

```
/kafka_2.12-2.5.0/bin/zookeeper-shell.sh \
        $zookeeper
```

```
ls /
[admin, 
brokers, ## Cluster에 포함된 Broker 구조 
 cluster, config, consumers, controller, controller_epoch, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper]
```

```
### Bash shell을 통해 Broker의 정보를 가져올수 있다 .
get /brokers/ids/0
{"listener_security_protocol_map":{"PLAINTEXT":"PLAINTEXT"},"endpoints":["PLAINTEXT://211.184.188.34:29095"],"jmx_port":-1,"host":"211.184.188.34","timestamp":"1689314222751","port":29095,"version":4}

get /brokers/ids/1 (현재 서버는 클러스터 구조가 되어있지 않아 브로커는 1개이다)
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /brokers/ids/1
```

```
### Bash Shell을 통해 Controller역할을하는 Broker 정보를 가져올수 있다. 
###### -> 다른 브로커들의 상태 체크 후, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더파티션을 재분배
get /controller
{"version":1,"brokerid":0,"timestamp":"1689314222832"}
```

```
### Bash Shell을 통해 저장된 토픽을 볼수 있다. 
ls /brokers/topics
[__consumer__offsets, __consumer_offsets, __test-group__offsets, hello.kafka.11]
```

---
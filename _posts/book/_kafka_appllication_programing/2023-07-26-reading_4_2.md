---
title:  "[카프카] 카프카 컨슈머"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 3장"
post-order: 5                

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-07-26
last_modified_at: 2023-07-26
---

### 카프카 Consumer

---

카프카 Consumer 설정

```java
Properties properties = new Properties();
// Broker 설정
properties.put(BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS); 
// Consumer Group 설정
properties.put(GROUP_ID_CONFIG, GROUP_ID);
// Auto Commit Off 
properties.put(ENABLE_AUTO_COMMIT_CONFIG, false);
properties.put(VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
```

카프카 Consume

```java
//브로커로부터 레코드를 가져올때 컨슈머 버퍼에 데이터를 1초간 기다리고, 버퍼에 쌓인 레코드를 List로 가져온다.
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
```

Consumer 에서 Broker를 통해 받아온 record 로그

```java
ConsumerRecord(
	topic = hello.kafka.11, 
	partition = 0, 
	leaderEpoch = 0,  // 파티션의 리더(Leader)가 변경될 때마다 증가하는 숫자
	offset = 21, 
	CreateTime = 1689659490649, 
	serialized key size = 6, 
	serialized value size = 4, 
	headers = RecordHeaders(headers = [], isReadOnly = false), 
	key = Pangyo, 
	value = test
)
```

### 컨슈머 중요 개념

---

1. **컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져간다.**

   ![Untitled](https://drive.google.com/uc?export=view&id=1Asw1mdl43wHzfsyAZ_5N-WnHxLu-XxHA)

2. **1개의 파티션은 최대 1개의 컨슈머에 할당 가능하다.**

   ![Untitled](https://drive.google.com/uc?export=view&id=1PmCRSJ-oPLzdI5ozg8kuykVJ2bWN8kj5)

   ![Untitled](https://drive.google.com/uc?export=view&id=1my_nnJ83SX33O2XX4Hz3Ylc9fmlD4yU4)

3. **컨슈머 그룹은 다른 컨슈머 그룹과 격리된다.**
  - `토픽 별 컨슈머 그룹의 오프셋을 관리`하여 읽어가는 데이터를 독립적으로 운영할수 있다.
  - Kafka로 Producing된 레코드들을 각각 컨슈머 그룹이 독립적으로 레코드를 처리한다.

![Untitled](https://drive.google.com/uc?export=view&id=1v1MfwY4QVyyWd7YRq74HfjoXmMhUaqky)

4. **컨슈머 장애가 발생시, 장애가 발생한 컨슈머에 할당된 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어간다. (`리밸런싱`)**
  - 이때 여러 브로커중 `코디네이터` 역할을 하는 브로커가 리밸런싱 작업을 처리한다.
  - 코디네이터 역할을 하는 브로커 확인 방법
    - `__consumer_offsets` 토픽의 리더 브로커가 코디네이터 역할을 같이한다.

      ```java
      // zshell 에서 확인
      //// "leader" : 0 -> 0번 브로커가 코디네이터 역할을 한다. 
      get /brokers/topics/__consumer_offsets/partitions/0/state
      {"controller_epoch":1,"leader":0,"version":1,"leader_epoch":0,"isr":[0]}
      ```

      ```java
      // kafka api로 확인 
      //// Leader : 0  -> 0번 브로커가 코디네이터 역할을 한다. 
      kafka-topics.sh \
              --bootstrap-server $broker \
              --describe \
              --topic __consumer_offsets \
      
      Topic: __consumer_offsets	PartitionCount: 50	ReplicationFactor: 1	Configs: compression.type=producer,cleanup.policy=compact,segment.bytes=104857600
        Topic: __consumer_offsets	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
      ```


4.1 리밸런싱 발생 조건

- 컨슈머가 추가되는 상황

![Untitled](https://drive.google.com/uc?export=view&id=19veAUZkyrnzHGLXF5ctQ9IeNn1t4whUG)

![Untitled](https://drive.google.com/uc?export=view&id=1ovUt2huonqC2v4AiNBhVpOA4RPFm_kTv)

- 컨슈머가 제외되는 상황

![Untitled](https://drive.google.com/uc?export=view&id=1xADq_1o8ydmEbcWZhroTLuggxmgsJJtb)

4.2 리밸런싱의 위험성

- 리밸런싱 도중에는 해당 컨슈머그룹의 컨슈머들이 토픽의 데이터를 읽을수 없다.

  → 이렇기 때문에 리밸런싱이 일어나는 작업은 트래픽없을때….

1. **컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 `커밋`을 통해 기록한다.**
  - 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇번째 가져갔는지  `__consumer_offsets 토픽`에 기록된다.
    - 기록되지 않는다면 해당 레코드가 중복 처리 될수 있다.

   5-1. 비명시적 오프셋 커밋

   → 개발자가 직접 커밋할 필요가 없다.

  - enable.auto.commit=true (default) 설정을 통해 동작한다.
  - [auto.commit.interval.ms](http://auto.commit.interval.ms) 값 마다 `처리한 레코드들의 offset`을 커밋한다.
  - 단점 : 커밋 주기가 돌아오기 전 컨슈머 장애 발생시 처리한 레코드들에 커밋을 하지 못해 중복 처리가 될 가능성이 있다.

   5-2 명시적 오프셋 커밋

   → 개발자가 직접 커밋하며, poll()을 통해 반환된 레코드의 `가장 마지막 오프셋을 기준으로 커밋`

    ```java
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
    // 동기 커밋
    consumer.commitSync();
    
    //비동기 커밋
    consumer.commitAsync((offsets, exception) -> {
               // do something
    });
    ```

2. **컨슈머 내부 구조**
- 컨슈머는 poll()때 브로커에서 레코드를 가져오는것이 아니라 컨슈머 내부에서 `Fetcher 인스턴스가` 생성되어 미리 레코드를 내부 큐로 가져온다.
- 사용자가 명시적으로 Poll() 메서드 호출시 컨슈머는 내부 큐에 있는 레코드를 반환하여 처리를 수행한다.

### 컨슈머 주요 옵션

---

- 필수옵션
  - bootstrap.servers : 브로커 호스트 이름
  - key.deserializer : 레코드의 메시지 키를 역직렬화하는 클래스 지정
  - value.deserializer : 레코드의 메세지값을 역직렬화하는 클래스
- 선택옵션
  - [group.id](http://group.id) : 컨슈머 그룹 아이디 지정
  - [auto.offset.res](http://auto.offset.rest)et : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우, 어느 오프셋부터 읽을지 설정
    - latest : 가장 최근에 넣은 offset부터`(default)`
    - earliest : 가장 오래 전에 넣은 offset부터
    - none : 커밋 기록이 없으면 오류를 반환하고, 커밋 기록이 있으면 기존 커밋 기록 이후부터
  - enable.auto.commit : 자동커밋으로 할지, 수동커밋으로 할지 선택
    - true `(default)`
  - [auto.commit.interval.ms](http://auto.commit.interval.ms) : auto commit 때 커밋 간격
    - 5000(5초) `(default)`
  - max.poll.records : poll()메서드를 통해 반환되는 레코드 개수를 지정한다
    - 500`(default)`
  - [session.timeout.ms](http://session.timeout.ms) : 컨슈머가 브로커와 heartbeat를 해당 시간내에 전송하지 않으면 컨슈머 장애로 인식 → 브로커에서 리밸런싱 발생
    - 10000 (10초) `(default)`
  - [heartbeat.interver.ms](http://heartbeat.interver.ms) : 하트비트 전송 시간
    - 3000(3초) `(default)`
  - [max.poll.interval.ms](http://max.poll.interval.ms) : poll() 메서드 호출 간격의 최대 시간.
    - poll()이후 다음 poll() 사이 간격이 이 시간보다 크면 컨슈머 장애로 인식한다
    - 300000(5분) `(default)`
  - isolation.level : 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼때 사용
    - read_committed : 커밋이 완료된 레코드만 읽는다.
    - read_uncommitted : 커밋여부와 상관없이 파티션에 있는 모든 레코드를 읽는다 `(default)`

### 동기오프셋 커밋

---

- 개별 레코드 단위로 커밋

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));

Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();
for (ConsumerRecord<String, String> record : records) {
    System.out.println(record);

    currentOffsets.put(
        new TopicPartition(record.topic(), record.partition()),
        new OffsetAndMetadata(record.offset() + 1, null)
    );

    System.out.println("====COMMIT START====");
    consumer.commitSync(currentOffsets);
    System.out.println("====COMMIT END====");
}
```

```java
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 41, CreateTime = 1689733792991, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)
====COMMIT START====
====COMMIT END====
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 42, CreateTime = 1689733793201, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2)
====COMMIT START====
====COMMIT END====
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 43, CreateTime = 1689733793388, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 3)
====COMMIT START====
====COMMIT END====
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 44, CreateTime = 1689733793574, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 4)
====COMMIT START====
====COMMIT END====
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 45, CreateTime = 1689733793759, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 5)
====COMMIT START====
====COMMIT END====
```

- poll()로 가져온 가장 마지막 레코드의 오프셋으로 커밋
  - 결국 마지막에 consumer.commitSync() 호출 전 에러가 발생하여 리밸런싱이 발생하면, poll()로 가져온 레코드들은 커밋이 되지 않은채 재처리된다.

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
System.out.println("POLL 결과 개수 ===> " + records.count());

for (ConsumerRecord<String, String> record : records) {
    System.out.println(record);
}
consumer.commitSync();
```

```java
POLL 결과 개수 ===> 5
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 46, CreateTime = 1689734100677, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 47, CreateTime = 1689734100858, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2)
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 48, CreateTime = 1689734101044, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 3)
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 49, CreateTime = 1689734101216, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 4)
ConsumerRecord(topic = hello.kafka.11, partition = 1, leaderEpoch = 0, offset = 50, CreateTime = 1689734101379, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 5)
```

### 비동기 오프셋 커밋

---

→ 커밋에 대한 응답을 기다리지 않는다. (callback으로 처리 가능)

- 개별 레코드 단위 커밋

```java
ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
**System.out.println("POLL 결과 개수 ===> " + records.count());**

Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>();

for (ConsumerRecord<String, String> record : records) {
    **System.out.println(record);** 
    currentOffsets.put(
        new TopicPartition(record.topic(), record.partition()),
        new OffsetAndMetadata(record.offset() + 1, null)
    );

    **System.out.println("====COMMIT START====");**
    consumer.commitAsync(currentOffsets, (
        (offsets, exception) -> **System.out.println("====COMMIT END====")**)
    );
}
```

```java
POLL 결과 개수 ===> 5
ConsumerRecord(topic = hello.kafka.11, partition = 2, leaderEpoch = 0, offset = 39, CreateTime = 1689734428424, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 2, leaderEpoch = 0, offset = 40, CreateTime = 1689734428612, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 2, leaderEpoch = 0, offset = 41, CreateTime = 1689734428784, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 3)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 2, leaderEpoch = 0, offset = 42, CreateTime = 1689734428972, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 4)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 2, leaderEpoch = 0, offset = 43, CreateTime = 1689734429134, serialized key size = -1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 5)
====COMMIT START====
====COMMIT END====
====COMMIT END====
====COMMIT END====
====COMMIT END====
====COMMIT END====
```

### 리밸런스 리스너를 가진 컨슈머

---

컨슈머 그룹에서 컨슈머가 추가 / 제거되면 파티션을 다른 컨슈머에게 재할당하는 과정인 `리밸런스`가 `코디네이터`에 의해 일어난다.

리밸런스 발생시 중복 처리하지 않게 하기 위해 `리밸런스 발생 시점에 처리한 데이터를 기준으로 커밋`을 시도해야 한다.

### 파티션 할당 컨슈머

---

→ 직접 컨슈머가 토픽 / 파티션에 할당되므로, 리밸런싱이 일어나지 않는다.

- 아래 코드를 통해 컨슈머를 특정 토픽의 특정 파티션에 매핑시킬수 있다.

```java
consumer.assign(Collections.singleton(new TopicPartition(TOPIC_NAME, 0)));
```

- 예시 (커스텀 파티셔너를 가진 프로듀서를 통해 각 파티션으로 레코드를 발생시킨다. )

```java
// 모든 레코드를 Consume하는 컨슈머
/bin/kafka-console-consumer.sh \
        --bootstrap-server $broker \
        --topic $1 \
        --property print.key=true \
        --property key.seperator="-" \
        --from-beginning

PARTITION_1	1
PARTITION_1	1
PARTITION_1	1
PARTITION_1	1
PARTITION_1	1
PARTITION_1	1
PARTITION_0	0
PARTITION_0	0
PARTITION_0	0
PARTITION_0	0
PARTITION_0	0
PARTITION_2	2
PARTITION_2	2
PARTITION_2	2
PARTITION_2	2
PARTITION_2	2
```

```java
// Partition 0 번에 있는 레코드만 컨슘하는 컨슈머
POLL 결과 개수 ===> 5
ConsumerRecord(topic = hello.kafka.11, partition = 0, leaderEpoch = 0, offset = 60, CreateTime = 1689735506114, serialized key size = 11, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = PARTITION_0, value = 0)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 0, leaderEpoch = 0, offset = 61, CreateTime = 1689735506132, serialized key size = 11, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = PARTITION_0, value = 0)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 0, leaderEpoch = 0, offset = 62, CreateTime = 1689735506132, serialized key size = 11, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = PARTITION_0, value = 0)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 0, leaderEpoch = 0, offset = 63, CreateTime = 1689735506132, serialized key size = 11, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = PARTITION_0, value = 0)
====COMMIT START====
ConsumerRecord(topic = hello.kafka.11, partition = 0, leaderEpoch = 0, offset = 64, CreateTime = 1689735506133, serialized key size = 11, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = PARTITION_0, value = 0)
====COMMIT START====
====COMMIT END====
```

### 컨슈머에 할당된 파티션 확인 방법

```java
Set<TopicPartition> assignment = consumer.assignment();
System.out.println(assignment);
---
[hello.kafka.11-0] (위 테스트에서 0번 파티션에만 매핑시켜놨기 때문이 이렇게 출력)
```

### 컨슈머의 안전한 종료

---

컨슈머가 정상적으로 종료되지 않으면, 컨슈머는 세션 타임아웃([session.timeout.ms](http://session.timeout.ms)) 이 발생할때 까지 컨슈머 그룹에 남기 때문에 레코드 소모가 되지 않아 LAG이 계속적으로 증가한다

- [session.timeout.ms](http://session.timeout.ms) 시간 + 리밸런싱 시간동안 레코드 처리 불가

→ 컨슈머를 안전하게 종료하기 위해 wakeup()메서드를 지원한다.

- wakeup()이 실행된 후 poll()이 호출되면 WakeUpException이 발생한다.

```java
consumer.wakeup(); 
// 지금은 여기서 호출하지만, Application비정상 종료에 대한 훅을 처리하는 곳에서 호출하면 될듯
try {
    consumer.poll(Duration.ofSeconds(1));
} catch (WakeupException e) {
    System.out.println("Consumer 종료 시작");
} finally {
    consumer.close(); // Consumer그룹에서 이 Consumer 제거
}

---
Consumer 종료 시작
```
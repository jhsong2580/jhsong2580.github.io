---
title:  "[카프카] 카프카 커넥트"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 3장"
post-order: 10

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-08-02
last_modified_at: 2023-08-02
---
# 6-0 카프카 커넥트


데이터 파이프라인 생성시 반복 작업을 줄이고 효율적인 전송을 위한 애플리케이션

- 파이프라인 생성 작업이 있을때 매번 프로듀서, 컨슈머 애플리케이션 배포 및 운영하는 방법은 비효율적이다.
- 커넥트는 `작업 형태를 템플릿으로 만들어놓은 커넥터`를 실행함으로써 반복작업을 줄일수 있다.
- 파이프라인 생성시 자주 반복되는 값들(토픽 이름, 파일 이름, 테이블 이름)을 파라미터로 받는 커넥터를 코드로 작성하면, 이후에 실행할땐 코드를 작성할 필요가 없어진다.
- 커넥터는 각 커넥터가 가진 고유한 설정을 입력받아 데이터 처리

### 커넥터 종류

---

1. 소스 커넥터
  - 프로듀서 역할
2. 싱크 커넥터
  - 컨슈머 역할
    
![Untitled](https://drive.google.com/uc?export=view&id=1ydwtIhWf-dL6M3fQinL5_5gbfiR2DGqD)

### 커넥터 구성 요소

---

- 오픈소스 커넥터는 직접 만들 필요가 없으며, 커넥터 jar파일을 다운로드 하여 사용할수 있음
  - HDFS, AWS S3, JDBC, ElasticSearch 커넥터 등이 공개되어있다.

1. 사용자가 커넥트에 커넥터 생성 명령을 내리면, 커넥트는 내부에 `커넥터`와 `태스크`를 생성
  1. 커넥터는 태스크를 관리한다.
  2. 태스크는 커넥터에 종속되는 개념으로 실직적인 데이터 처리를 한다.
    - 태스크는 실직적인 데이터 처리를 하므로, 데이터 처리를 정상적으로 하는지 확인하기 위해서는 각 태스크의 상태를 확인해야한다.
2. 사용자가 커넥터를 사용하여 파이프라인을 생성할 때 `컨버터`와 `트랜스폼` 기능을 옵션으로 추가 가능
  1. 컨버터는 데이터 처리를 하기 전에 스키마를 변경하도록 도와준다 .
    1. JsonConverter, StringConverter, ByteArrayConverter
    2. CustomConverter 생성 가능
  2. 트랜스톰은 데이터 처리시 각 메세지 단위로 데이터를 간단하게 변환하기 위한 용도
    1. Json데이터를 커넥터에서 사용할 때 트랜스폼을 사용하면 특정 키를 삭제 하거나 추가할수 있다.
      - Cst, Drop, ExtractField등을 제공


### 커넥트를 실행하는 방법

---

1. 단일 모드 커넥트
- 단일 애플리케이션으로 실행된다.
- 커넥터를 정의하는 파일을 작성하고, 해당 파일을 참조하는 단일 모드 커넥트를 실행함으로써 파이프라인 생성 가능
- 1개 프로세스만 실행된다.

![Untitled](https://drive.google.com/uc?export=view&id=1M2M1XicfiqgE7iwFL5VCRZpYTY54iEdu)

1. 분산 모드 커넥트
- 2대 이상의 서버에서 클러스터 형태로 운영
- 2개 이상의 커넥트가 클러스터로 묶이면 1개 커넥트가 장애나도 문제없다
- 커넥트가 실행되는 서버 개수를 늘림으로써 무중단으로 `스케일아웃`이 가능하다

![Untitled](https://drive.google.com/uc?export=view&id=1L89CPRVA7XPyZaB83dZVeJB5aKN7JqCq)
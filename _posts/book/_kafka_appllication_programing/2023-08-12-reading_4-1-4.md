---
title:  "[카프카] # 4. 스프링 카프카 프로듀서
excerpt: "아파치 카프카 애플리케이션 프로그래밍 4장"
post-order: 14

tag : ["kafka"]
sidebar:
nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-08-12
last_modified_at: 2023-08-12
# 4-1. 스프링 카프카 프로듀서

스프링 카프카는 기존 카프카 클라이언트 라이브러리를 래핑하여 만든 라이브러리

- 카프카 클라이언트에서 사용하는 여러가지 패턴을 미리 제공
- 어드민, 컨슈머, 프로듀서, 스트림즈 기능을 제공한다.

### 1. 스프링 카프카 프로듀서

---

`카프카 템플릿`이라 불리는 클래스를 사용하여 데이터를 전송할수 있다.

- 카프카 템플릿은 프로듀서 팩토리 클래스를 통해 생성할수 있다.
- build.gradle

    ```java
    
    implementation 'org.springframework.boot:spring-boot-starter'
    
    // kafka
    implementation 'org.springframework.kafka:spring-kafka'
    ```


### 1-1. 카프카 템플릿 사용 방법

---

1. 기본 카프카 템플릿

  1. yml에 카프카 정보 추가

  - spring.kafka.producer : broker Endpoint
  1. KafkaTemplate 주입
    - send 메서드가 오버로딩 되어있다.

    ```java
    @Autowired
    KafkaTemplate<Integer, String> template;
    
    void doSomething() {
    	template.send(TOPIC_NAME, KEY, VALUE);
    	template.send(TOPIC_NAME, Partition#, KEY, VALUE);
    	template.send(TOPIC_NAME, KEY, VALUE);
    }
    ```


1. 커스텀 카프카 템플릿
- 프로듀서 팩토리를 통해 만든 카프카 템플릿 객체를 빈으로 등록하여 사용
  - 프로듀서에 필요한 각종 옵션을 선언하여 사용이 가능하다.
- 각 클러스터 별 카프카 템플릿을 빈으로 등록하여 사용할수 있다.

```java
@Bean
public KafkaTemplate<String, String> customKafkaTemplate() {
    HashMap<String, Object> prop = new HashMap<>();
		// Broker정보
    prop.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
		// Key / Value 직렬화 클래스
    prop.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    prop.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
		// 모든 팔로워 파티션에 레코드가 적재될때까지 확인
    prop.put(ProducerConfig.ACKS_CONFIG, "all");

    DefaultKafkaProducerFactory<String, String> pf = new DefaultKafkaProducerFactory<>(
        prop);
    
    return new KafkaTemplate<>(pf);
}
```

- 아래와 같이 Record를 적재할수 있다.

```java
public void produce() {
  ListenableFuture<SendResult<String, String>> future = customKafkaTemplate.send(
      "hello.kafka.12", "test");

  future.addCallback(
      new KafkaSendCallback<String, String>() {
          @Override
          public void onSuccess(SendResult<String, String> result) {
              log.info("kafka produce result : {}", result.toString());
          }

          @Override
          public void onFailure(KafkaProducerException ex) {
              log.error("kafka produce error : {}", ex.getMessage());
          }
      }
  );
}

---
 kafka produce result : SendResult [producerRecord=ProducerRecord(topic=hello.kafka.12, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value=test, timestamp=null), recordMetadata=hello.kafka.12-0@20]
```
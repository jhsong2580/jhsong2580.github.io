---
title:  "[카프카] 카프카 프로듀서"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 3장"
post-order: 4                            

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-07-25
last_modified_at: 2023-07-25
---


### 프로듀서 API

---

- 브로커의 특정 토픽의 파티션에 전송
- 프로듀서는 데이터를 직렬화 하여 카프카 브로커로 보내기 때문에 자바에서 선언한 모든 형태를 브로커로 전송할수 있다.

### 카프카 프로듀서

---

카프카 Producer 설정

```java
Properties properties = new Properties();
// Broker Endpoint 설정
properties.put(BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);
// Key 직렬화 Class 
properties.put(KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
// Value 직렬화 Class
properties.put(VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
// Custom Partitioner 설정 
properties.put(PARTITIONER_CLASS_CONFIG, CustomPartitioner.class);

this.kafkaProducer = new KafkaProducer<String, String>(properties);
```

카프카 Produce

```java
// Record Produce
this.kafkaProducer.send(record);

// 프로듀서 내부 버퍼에 가지고 있던 레보드 배치를 브로커로 전송
this.kafkaProducer.flush(); 
```

Producer 에서 보내기 전 record 로그

```java
ProducerRecord(
	topic=hello.kafka.11, // 보내는 토픽
	partition=null,       // 레코드를 전송하기 전이여서 partition이 정해져 있지 않다.
	headers=RecordHeaders(headers = [], isReadOnly = true), 
	key=Pangyo,         
	value=test,  
	timestamp=null        // 레코드의 timestamp는 브로커에 적재 될때 브로커가 설정하기 때문에 null이다.
)
```

### 프로듀서 중요 개념

---

프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

![Untitled](https://drive.google.com/uc?export=view&id=1DPnwuAIRWUJ4mN6GCsC9oU1FFQOiH4_1)

KafkaProducer 인스턴스가 send()메서드를 호출하면 아래의 동작이 이뤄진다.

1. Partitioner을 통해 어느 파티션으로 적재될지 정해진다.
  1. 카프카 2.5버전은 Default로 `UniformStickyPartitioner`를 실행한다.
    - 메세지 키가 있으면 메세지 키의 해시값고 파티션을 매칭한다.
    - 메세지 키가 없으면 Accumulator에서 배치로 레코드가 다 묶일때까지 기다렸다가 데이터를 동일한 파티션에 전송한다.
2. 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 `Accumulator`에 데이터를 버퍼로 쌓아두고, Sender를 통해 발송한다

```java
//todo Accumulator 대기 로직 조회 
```

### 프로듀서 주요 옵션

---

- 필수옵션
  1. bootstrap.servers : 프로듀서가 데이터를 젓오할 대상 카프카 클러스터의 브로커 호스트 이름
    - ex) `211.184.188.33:29095, 211.184.188.34:29095, 211.184.188.35:29095`
  2. key.serializer : 레코드의 메세지 키를 직렬화하는 클래스를 지정한다.
  3. value.serializer : 레코드의 메세지 값을 직렬화하는 클래스를 지정한다.

- 선택옵션
  1. acks : 프로듀서가 전송한 데이터가 브로커들에 정상적으로 저장되었는지 전송 성공 여부 확인
    - 0 : 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관 없이 성공으로 판단
    - 1`(default)` : 리더 파티션에 데이터가 저장되면 전송 성공으로 판단
    - -1 : 토픽의 min.insync.replicas 개수에 해당하는 리더파티션과 팔로워 파티션에 데이터가 저장되면 성공
  2. buffer.memory : 브로커로 전송할 데이터를 배치로 모으기 위해 설정할 버퍼 메모리 양 지정
    - 33554432(32MB)`(default)`
  3. retries : 프로듀서가 브로커로부터 에러를 받고 난 뒤 재전송을 시도하는 횟수 지정
    - 2억 `(defualt)`
  4. batch.size : 배치로 전송할 레코드 최대 용량을 지정
    - 너무 작게 전송하면 자주 보내기 때문에 네트워크 부담이 생긴다
    - 너무 크면 메모리를 더 많이 사용하게 된다.
    - 16384`(default)`
  5. [linger.ms](http://linger.ms) : 배치를 전송하기 전까지 기다리는 최소 시간
    - 0`(default)`
  6. partitioner.class : 레코드를 파티션에 전송할때 적용하는 파티셔너 클래스
  7. enable.idempotence : 멱등성 프로듀서로 동작할지 여부
    - false `(default)`
  8. [transactional.id](http://transactional.id) : 프로듀서가 레코드를 전송할때 레코드를 트랜잭션 단위로 묶을지 여부 설정
    - null `(default)`

### 메세지 키를 가진 데이터를 전송하는 프로듀서

---

아래와 같이 각 키 별로 5개의 레코드를 Produce를 했다고 했을때

```java
for(int i=0; i<5; i++) {
      kafkaProducer.send(partition0);
      kafkaProducer.send(partition1);
      kafkaProducer.send(partition2);
}
```

1. **아래와 같은 Custom Partitioner 설정시**

```java
@Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes,
        Cluster cluster) {
        if(keyBytes == null) {
            throw new InvalidRecordException("Needs Message Key");
        }

        if (((String) key).equals("PARTITION_0")) {
            return 0;
        }

        if (((String) key).equals("PARTITION_1")) {
            return 1;
        }

        if (((String) key).equals("PARTITION_2")) {
            return 2;
        }
}
```

**1 - result**

```java
// partition 0
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 0 --topic hello.kafka.11
0
0
0
0
0

// partition 1
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 1 --topic hello.kafka.11
1
1
1
1
1

// partition 2
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 2 --topic hello.kafka.11
2
2
2
2
2
```

1. Default Partitioner로 설정시 (무작위로 전달된다)

```java
// partition 0
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 0 --topic hello.kafka.11
0
0
0
0
0

// partition 1
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 1 --topic hello.kafka.11
1
1
1
1
1

// partition 2
kafka-console-consumer.sh --bootstrap-server 211.184.188.34:29095 --partition 2 --topic hello.kafka.11
1
2
1
2
1
2
1
2
1
2
```

### 브로커 정상 전송 여부를 확인하는 프로듀서

---

1. KafkaProducer의 send()는 Future를 반환하여 동기적로 동작할수 있다.

```java
Future<RecordMetadata> produceResult = kafkaProducer.send(partition1);
RecordMetadata recordMetadata = produceResult.get();
System.out.println("적재된 레코드 결과 ==> " + recordMetadata);

---
적재된 레코드 결과 ==> hello.kafka.11-1@39 // 1번 파티션의 39번 오프셋에 저장됨을 알수 있다. 
```

1. Produce Callback 을 설정하여 비동기적으로 전송 여부를 확인할수 있다.

```java
public class ProducerCallback implements Callback {

    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            System.out.println("ERROR");
        } else {
            System.out.println("적재된 레코드 결과 ==> " + metadata);
        }
    }
}

---
ProducerCallback callback = new ProducerCallback();
kafkaProducer.send(partition1, callback);

---
적재된 레코드 결과 ==> hello.kafka.11-1@40 // 1번 파티션의 40번 오프셋에 저장됨을 알수 있다. 
```
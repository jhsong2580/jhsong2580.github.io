---
title:  "[카프카] 토픽과 파티션"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 4장"
post-order: 11

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-08-03
last_modified_at: 2023-08-03
---
# 1. 토픽과 파티션

토픽은 카프카의 시작과 끝이다.

- 토픽이 삭제되면 데이터는 삭제되고 파이프라인은 중단된다.

지금부터 토픽을 사용함에 있어 발생하는 여러가지 운영상 고려사항을 알아보자.

### 적정 파티션 개수

---

토픽 최초 생성 시 파티션의 개수를 정하는 데 고려할점 3가지

1. 데이터 처리량
  - `파티션`은 카프카 `병렬 처리의 핵심`. 파티션이 많아질수록 매핑되는 컨슈머 개수가 늘어난다.

    → 데이터 처리량을 측정하여 파티션 개수를 설정해야한다.

    - 부하 테스트를 통해 스펙 테스트를 해보자. (스펙 테스트는 운용환경에서 하는것이 정확하다)

    ```java
    프로듀서 전송 데이터 량 < 컨슈머 데이터 처리량 * 파티션 개수
    ```

  - 데이터의 지연이 허용되지 않는 서비스라면 프로듀서가 보내는 데이터의 최대치를 기준으로 하자.
    - 지연이 허용된다면 최대치를 기준으로 하지 않아도 된다.
2. 메시지 키 사용 여부
  - 메세지 키를 사용함과 동시에 데이터 처리 순서를 지켜야 하는 경우에 고려

    → 한 파티션에 대해선 작업의 순서가 지켜진다.

    → default partitioner를 사용한다고 가정했을때, Key를 사용하지 않으면 어느 파티션에 레코드가 적재될지 장담할수 없다.

    - 순서가 지켜져야 한다면 반드시 key를 설정하여 동일한 파티션에 적재되도록 하자.
    - 기존의 키 매칭을 그대로 가져가면서 파티션 개수를 변경시키려면, 커스텀 파티셔너를 개발해야하고 적용해야 한다.
3. 브로커, 컨슈머 영향도
  - 파티션은 각 `브로커의 파일 시스템`을 사용하기 때문에, 파티션이 늘어나는 만큼 브로커에서 접근하는 파일 개수가 많아진다.
    - but OS에서는 프로세스 당 열수있는 파일의 최대 개수를 제한하고 있다.

      → 이런 장애를 방지하기 위해선 각 브로커 당 파티션 개수를 모니터링 해야 한다.

    - 데이터 량이 많아져서 파티션 개수를 늘려야 하는 상황이라면, 브로커 당 파티션 개수를 확인하고 진행한다.
      - 브로커가 관리하는 파티션 개수가 많다면 `브로커 개수를 추가`하는 방안도 고려해야한다.

### 토픽 정리 정책

---

토픽의 데이터는 시간 또는 용량에 따라 삭제 규칙을 적용할수 있다.

- cleanup.policy를 통해 데이터를 삭제할수 있다. (아래 2개의 옵션을 정할수 있다.)
  - delete : 완전삭제
  - compact : 압축. 동일 메세지 키의 가장 오래된 데이터를 삭제

1. 토픽 삭제 정책(cleanup.policy → delete)
- 토픽의 데이터를 삭제하며, 삭제할때는 `세그먼트 단위로 삭제를 진행`
- 세그먼트는 `파티션마다 별개로 생성`되며, `파일 이름은 오프셋중 가장 작은 값`이 된다.
- 세그먼트는 여러 조각으로 나뉘는데, `segment.bytes` 옵션으로 1개의 `세그먼트 크기를 설정`할수 있다.
  - segment.bytes 크기보다 커지면, 기존 세그먼트를 닫고 새로운 세그먼트를 열어 데이터를 저장한다.

    → `active segment` 라 한다.

- 삭제 정책이 실행되는 시점은 `시간 혹은 용량이 기준`이 된다.
  - [`retention.ms`](http://retention.ms) : 토픽의 데이터를 유지하는 기간을 밀리초로 설정
    - 카프카는 일정 주기마다 세그먼트 파일의 마지막 수정시간과 retention.ms를 비교하는데, 마지막 수정 시간이 retention.ms를 넘어가면 세그먼트는 삭제된다.
  - `retention.bytes` : 이 용량을 넘어간 세그먼트 파일들은 삭제된다.

```java
로그 세그먼트 (3-1 장에서 잠깐 나왔다.)
- 카프카 데이터 삭제 단위이며, 파일로 이루어져 있다. 
- 다수의 데이터가 들어가 있기 때문에 "특정 데이터만 삭제"할수는 없다. 
- 데이터가 쌓이는 동안 파일 시스템으로 열려있다.
```

1. 토픽 압축 정책(cleanup.policy → compact)
- 메세지 키 별로 해당 메세지 키의 레코드 중 오래된 데이터를 삭제하는 정책
  - KTable처럼 가장 최근의 레코드만 필요한 경우 압축 정책이 매우 유용하다.
- 압축 정책은 `액티브 세그먼트를 제외한 나머지 세그먼트` 들에 한해서 데이터를 처리한다.
  - `min.cleanable.dirty.ratio` : 압축 시작 시점.
    - tail영역과 head영역의 레코드 개수 비율
      - Tail영역 : 압축 정책에 의해 압축이 완료된 레코드
      - Head영역 : 압축이 되기전 레코드

    ```java
    cleanable.dirty.ratio = 더티 레코드 개수 / (클린 레코드 개수 + 더티 레코드 개수)
    ```


### ISR(In-Sync-Replicas)

---

리더 파티션과 팔로워 파티션이 모두 싱크가 된 상태

- 리더파티션과 팔로워 파티션의 max offset이 같아야 한다. (똑같은 데이터를 가지고 있어야함)

프로듀서는 특정 파티션에 데이터를 저장하는 작업은 리더 파티션을 통해 처리한다.

- 리더 파티션에 오프셋이 증가하면, `팔로워 파티션이 위치한 브로커`는 `리더 파티션의 레코드를 복제`한다.

  → 이 시간차 때문에 ISR이 항상 지켜질 수는 없다.

- 시간차로 인해 발생하는 `차이`를 모니터링 하기 위해 리더 파티션은 `replica.log.time.max.ms`만큼의 주기를 가지고 `팔로워 파티션이 데이터를 복제하는지 확인`한다.
  - `[replica.log.time.max.ms](http://replica.log.time.max.ms)` : 이 시간보다 더 긴 시간동안 팔로워 파티션이 데이터를 가져가지 않는다면, ISR 그룹에서 제외한다.

ISR로 묶인 리더파티션과 팔로워파티션은 저장하고 있는 데이터가 모두 동일하기 때문에 팔로워 파티션은 리더 파티션으로 새로 선출될 자격을 가진다.

- `unclean.leader.election.enable` : ISR이 아닌 팔로워 파티션도 리더 파티션으로 선출 가능 여부
  - false : ISR이 아닌 파티션을 리더로 선출하지 않는다.
  - true : ISR이 아닌 파티션도 리더로 선출될수 있다.
    - 리더 파티션이 존재하는 브로커가 다시 시작할때까지 대기한다. (서비스 중단)
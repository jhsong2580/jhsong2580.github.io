---
title:  "[카프카] 스트림즈DSL"
excerpt: "아파치 카프카 애플리케이션 프로그래밍 3장"
post-order: 8  

tag : ["kafka"]
sidebar:
  nav: "docs"
categories: ["book", "_kafka_application_programing"]


date: 2023-07-29
last_modified_at: 2023-07-19
---
# 5-1. 스트림즈DSL

스트림즈 DSL은 레코드의 흐름을 추상화한 3가지 개념이 있다.

1. KStream
2. Ktable
3. GlobalKTable

![Untitled](https://drive.google.com/uc?export=view&id=1grHPYSLLDZCB3mNHPRDGQRhPwawu25od)

### KStream

---

- 레코드의 흐름을 표현. 메세지키와 값으로 구성되어 있다.
- 토픽에 존재하는 모든 레코드가 출력된다.
  
![Untitled](https://drive.google.com/uc?export=view&id=1AesvC13nYs8nIZIc3nxBZTEBRUVY0nc2)

### KTable

---

- KStream과는 다르게 메세지 키를 기준으로 묶어서 사용한다.
- 메세지 키 별 `최신의 레코드를 출력한다.`

![Untitled](https://drive.google.com/uc?export=view&id=1Q9tvR2JWKuidEL-AsJ4HVVzwDnfuxXBQ)

### GlobalKTable

---

- KTable과 동일하게 메세지 키를 기준으로 최신의 레코드를 제공한다.
- KTable로 선언된 토픽은 `1개 파티션의 1개 태스크에 할당`
- GlobalKTable로 선언된 토픽은 `모든 파티션 데이터가 각 태스크에 할당`

### Kstream과 KTable의 조인

---

Kstream과 KTable은 반드시 코파티셔닝 되어있어야 조인이 가능하다.

```java
코파티셔닝 : 조인을 하는 2개 토픽의 파티션 개수가 동일하고, 파티셔닝 전략이 동일하다.
-> 한 태스크에 같은 방식으로 레코드가 저장됨을 보장받는다.
```

![Untitled](https://drive.google.com/uc?export=view&id=1TjafNQQl1sV_-nZBnuRC3qaoIniRwLvr)

- 코파티셔닝이 되지 않은 2개의 토픽을 조인할때 `TopologyException`이 발생한다.
- KStream 과 KTable 조인시 코파티셔닝이 되어있지 않다면 `리파티셔닝`하는 과정을 거쳐야 한다.

```java
리파티셔닝 : 새로운 토픽에 새로운 메세지 키를 가지도록 재배열하는 과정
- 이때 토픽에 기존 데이터를 중복해서 생성할 뿐만 아니라 파티션을 재배열 하기 위해 프로세싱 하는 과정도 거쳐야 한다. 
```

→ 코파티셔닝을 하기 싫으면 GlobalKTable로 정의하여 조인하자

### 스트림즈DSL 주요 옵션

---

필수옵션

- bootstrap.servers : 브로커호스트:포트 1개 이상
- [application.id](http://application.id) : 스트림즈 애플리케이션을 구분하기위한 고유한 아이디. 다른 로직을 가진 스트림즈 애플리케이션은 서로 다른 id값을 가져야 한다.
  - 해당 ID값으로 `Consumer Group`이 생성된다.

선택옵션

- default.key.serde : 레코드 메세지 키를 직렬화/역직렬화 하는 클래스
  - Serdes.ByteArray().getClass().getName `default`
- default.value.serde : 레코드 메세지 값을 직렬화/역직렬화 하는 클래스
  - Serdes.ByteArray().getClass().getName `default`
- num.stream.threads : 스트림 프로세싱 실행시 실행될 스레드 개수
  - 1 `default`
- state.dir : rocksDB저장소가 위치할 디렉토리 지정

  rocksDB : 페이스북이 개발한 고성능 K-V DB

  - 스트림즈가 상태기반 데이터 처리할떄 로컬 저장 요소로 사용한다.
  - /tmp/kafka-streams `default`

### 스트림즈DSL - stream(), to()

---

1. stream : 특정 토픽을 KStream형태로 가져오기 위함 `(소스 프로세서)`
2. to : KStream 데이터를 특정 토픽으로 저장하기 위함 `(싱크 프로세서)`

- 코드

```java
StreamsBuilder builder = new StreamsBuilder();
KStream<String, String> stream = builder.stream(SRC_TOPIC_NAME);
stream.to(TARGET_TOPIC_NAME);

KafkaStreams streams = new KafkaStreams(builder.build(), properties);
streams.start();
```

- SRC_TOPIC_NAME 으로 record produce

```java
./produce_record_kv.sh  SRC_TOPIC_NAME
>key:value
>key:value1
```

- TARGET_TOPIC_NAME 으로 Produce 확인

```java
./consume_record_with_key.sh  TARGET_TOPIC_NAME
key	value
key	value1
```

### 스트림즈DSL - filter()

- `스트림 프로세서` 로써 특정 조건에 맞는 레코드만 골라낸다.
  
![Untitled](https://drive.google.com/uc?export=view&id=1YGzxc0y4Skdl66CZ-i3tzwZm5eTDrqx-)

- 코드

```java
StreamsBuilder builder = new StreamsBuilder();
builder.<String, String>stream(TOPIC_NAME)
    .filter((key, value) -> key.length() > 5) // Key 길이가 5 이상일때만 Record를 전달한다.
    .to(TARGET_TOPIC_NAME);

KafkaStreams streams = new KafkaStreams(builder.build(), properties);
streams.start();
```

- SRC_TOPIC_NAME 으로 record produce

```java
./produce_record_kv.sh  SRC_TOPIC_NAME
>key:can not send
>key1:can not send
>key11:can not send
>key111:can send
```

- TARGET_TOPIC_NAME 으로 Produce 확인 (key 길이가 5를 초과한 `key111` 에 대한 레코드만 전달)

```java
./consume_record_with_key.sh  TARGET_TOPIC_NAME
key111	can send
```

### 스트림즈DSL - KTable과 KStream을 join()

---

- KTable과 KStream은 메세지 키를 기준으로 조인할수 있다.

![Untitled](https://drive.google.com/uc?export=view&id=1En7et8ZeW6axL2wfzjzKUPWguMrzk6CR)

- 준비물 : 토픽 3개
  - hello.kafka.11 `(TRG_TOPIC)`

    ```java
    ./display_topic_details.sh hello.kafka.11
    Topic: hello.kafka.11	PartitionCount: 3	ReplicationFactor: 1	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.11	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
    ```

  - hello.kafka.12 `(SRC_TOPIC_1)` / `KTable`

    ```java
    ./display_topic_details.sh hello.kafka.12
    Topic: hello.kafka.12	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.12	Partition: 0	Leader: 1	Replicas: 1,0	Isr: 1,0
    Topic: hello.kafka.12	Partition: 1	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.12	Partition: 2	Leader: 2	Replicas: 2,1	Isr: 2,1
    ```

  - hello.kafka.13 `SRC_TOPIC_2` / `KStream`

    ```java
    ./display_topic_details.sh hello.kafka.13
    Topic: hello.kafka.13	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.13	Partition: 0	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.13	Partition: 1	Leader: 2	Replicas: 2,1	Isr: 2,1
    Topic: hello.kafka.13	Partition: 2	Leader: 1	Replicas: 1,0	Isr: 1,0
    ```

- 코드

    ```java
    StreamsBuilder sb = new StreamsBuilder();
    KTable table = sb.<String, String>table(SRC_TOPIC_1);
    KStream stream = sb.<String, String>stream(SRC_TOPIC_2);
    
    stream.join(table,
        (src1, src2) -> "Join with " + src1 + " " + src2
    ).to(TRG_TOPIC);
    
    KafkaStreams kafkaStreams = new KafkaStreams(sb.build(), properties);
    kafkaStreams.start();
    ```

- 결과 - 아래 표는 두 토픽 다 같은 key를 통해 생성한다고 가정한다.
  - Kstream으로 데이터를 추가할때마다, 해당 키의 최상단 레코드와 조인한다.

  | SRC_TOPIC_1(KTable) | SRC_TOPIC_2(KStream) | TRG_TOPIC |
  | --- | --- | --- |
  | src1               |  |  |
  |                    | src2 | Join with src2 src1 |
  |                    | src2_1 | Join with src2_1 src1 |
  |                    | src2_2 | Join with src2_2 src1 |
  | src1_1             |  |  |
  | src1_2             |  |  |
  |                    | src2_3 | Join with src2_3 src1_2 |


### 스트림즈DSL - GlobalKTable과 KStream을 Join

---

- GlobalKTable은 모든 테스크에 레코드가 저장되기 때문에 파티션이 달라도 정상동작함
- 준비물 : 토픽 3개
  - hello.kafka.11 `(TRG_TOPIC)`

    ```java
    ./display_topic_details.sh hello.kafka.11
    Topic: hello.kafka.11	PartitionCount: 3	ReplicationFactor: 1	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.11	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
    ```

  - hello.kafka.14 `(SRC_TOPIC_1)` / `GlobalKTable`

    ```java
    ./display_topic_details.sh  hello.kafka.14
    Topic: hello.kafka.14	PartitionCount: 2	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.14	Partition: 0	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.14	Partition: 1	Leader: 2	Replicas: 2,1	Isr: 2,1
    ```

  - hello.kafka.13 `SRC_TOPIC_2` / `KStream`

    ```java
    ./display_topic_details.sh hello.kafka.13
    Topic: hello.kafka.13	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.13	Partition: 0	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.13	Partition: 1	Leader: 2	Replicas: 2,1	Isr: 2,1
    Topic: hello.kafka.13	Partition: 2	Leader: 1	Replicas: 1,0	Isr: 1,0
    ```

- 코드

    ```java
    stream.join(table,
        (srcKey1, srcKey2) -> srcKey1,
        (srcVal1, srcVal2) -> "Join with " + srcVal1 + " " + srcVal2
    ).to(TRG_TOPIC);
    
    KafkaStreams kafkaStreams = new KafkaStreams(sb.build(), properties);
    kafkaStreams.start();
    ```

- 결과
  - Kstream으로 데이터를 추가할때마다, GlobalKTable에서 해당 키의 최상단 레코드와 조인한다.

  | (SRC_TOPIC_1) / KTable | SRC_TOPIC_2 / KStream | TRG_TOPIC |
      | --- | --- | --- |
  | src1 |  |  |
  |  | src2 | Join with src2 src1 |
  |  | src2_1 | Join with src2_1 src1 |
  |  | src2_2 | Join with src2_2 src1 |
  | src1_1 |  |  |
  | src1_2 |  |  |
  |  | src2_3 | Join with src2_3 src1_2 |


### 스트림즈DSL - KStream과 KStream간 Join

---

- 준비물 : 토픽 3개
  - hello.kafka.11 `(TRG_TOPIC)`

    ```java
    ./display_topic_details.sh hello.kafka.11
    Topic: hello.kafka.11	PartitionCount: 3	ReplicationFactor: 1	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.11	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
    Topic: hello.kafka.11	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
    ```

  - hello.kafka.12 `(SRC_TOPIC_1)` / `KStream`

    ```java
    ./display_topic_details.sh hello.kafka.12
    Topic: hello.kafka.12	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.12	Partition: 0	Leader: 1	Replicas: 1,0	Isr: 1,0
    Topic: hello.kafka.12	Partition: 1	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.12	Partition: 2	Leader: 2	Replicas: 2,1	Isr: 2,1
    ```

  - hello.kafka.13 `SRC_TOPIC_2` / `KStream`

    ```java
    ./display_topic_details.sh hello.kafka.13
    Topic: hello.kafka.13	PartitionCount: 3	ReplicationFactor: 2	Configs: segment.bytes=1073741824,retention.ms=172800000
    Topic: hello.kafka.13	Partition: 0	Leader: 0	Replicas: 0,2	Isr: 0,2
    Topic: hello.kafka.13	Partition: 1	Leader: 2	Replicas: 2,1	Isr: 2,1
    Topic: hello.kafka.13	Partition: 2	Leader: 1	Replicas: 1,0	Isr: 1,0
    ```

- 코드
  - JoinWindows설정이 생겼다.
    - 각 Stream이 상대 Stream에서 데이터를 가져올때 5초 동안 쌓인 데이터 모두와 조인한다.

    ```java
    stream1.join(stream2,
        (srcTopic1Value, srcTopic2Value) -> "Join with " + srcTopic1Value + " " + srcTopic2Value,
        JoinWindows.of(Duration.ofSeconds(5L))
    ).to(TRG_TOPIC);
    
    KafkaStreams kafkaStreams = new KafkaStreams(sb.build(), properties);
    kafkaStreams.start();
    ```


- 결과
  - 각 토픽에 레코드가 추가될때 상대 토픽의 Window내에 있는 모든 레코드와 조인하여 결과를 출력한다.
  - 어느시점부터(`SRC_TOPIC_2`에 `src2_3`을 추가했을때) `SRC_TOPIC_1`에 레코드들이 JoinWindow를 벗어나며 Join결과가 나오지 않게된다.
  - `SRC_TOPIC_1`에 레코드를 추가했을때 `SRC_TOPIC_2` 에서 JoinWindow내에 있는 레코드들과 모두 Join한다.

  | SRC_TOPIC_1(KStream) | SRC_TOPIC_2(KStream) | TRG_TOPIC(Result)                                                                                  |
  | --- |----------------------------------------------------------------------------------------------------| --- |
  |  src1           |  |                                                                                                    |
  |  | src2           | Join with src2 src1                                                                                |
  |  | src2_1         | Join with src2_1 src1                                                                              |
  |  | src2_2         | Join with src2_2 src1                                                                              |
  |  src1_1         |  | Join with src1_1 src2, Join with src1_1 src2_1, Join with src1_1 src2_2                            |
  | src1_2 |  | Join with src1_2 src2, Join with src1_2 src2_1, Join with src1_2 src2_2                            |
  |  | src2_3 | Join with src1_1 src2_3, Join with src1_2 src2_3                                                   |
  |  | src2_3 | Join with src1_2 src2_3                                                                            |
  |  | src2_3 |                                                                                                    |
  |  | src2_3 |                                                                                                    |
  | src1_3 |  | Join with src1_3 src2_3, Join with src1_3 src2_3, Join with src1_3 src2_3, Join with src1_3 src2_3 |